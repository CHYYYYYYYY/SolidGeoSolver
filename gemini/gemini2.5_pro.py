# -*- coding: utf-8 -*-
import openai
import PIL.Image
import os
import json
import time
import socket
import socket
from tqdm import tqdm
from pydantic import BaseModel, Field
from typing import List, Dict, Any
import base64
from io import BytesIO
import sys

# Windowsç¼–ç ä¿®å¤
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')

# --- API configuration (Google Generative AI) ---
# Provide Google API keys via environment variable:
#   set GOOGLE_API_KEYS="KEY1,KEY2,KEY3" (or setx on Windows), or set GOOGLE_API_KEY (single)
GEMINI_API_BASE = "http://aicanapi.com/v1"
GEMINI_MODEL = "gemini-2.5-pro"
API_KEYS: List[str] = [
    "sk-8XbeoWmUgJy7muDhf4IswkRPrBjMmXBImOHCIP55NE0eh7le",
    "sk-cJIqFNxykfIFec19QUbIuwmQn6NoHLAyMD3lADfkLotYVOcI"
]
if not API_KEYS:
    print("âš ï¸  No Google API keys found. Set env var 'GOOGLE_API_KEYS' (comma-separated) or 'GOOGLE_API_KEY' before running.")


# API Key è½®è¯¢ç´¢å¼•å’ŒçŠ¶æ€è¿½è¸ª
current_key_index = 0
exhausted_keys = set()  # è®°å½•å·²è€—å°½é…é¢çš„ keys

def get_next_api_key():
    """è½®è¯¢è·å–ä¸‹ä¸€ä¸ªå¯ç”¨çš„ API Key"""
    global current_key_index
    if not API_KEYS:
        raise RuntimeError("No API keys configured. Please set env var AICAN_API_KEYS (comma-separated) or AICAN_API_KEY/GOOGLE_API_KEY.")
    attempts = 0
    # Round-robin through available keys; skip those marked exhausted
    while attempts < len(API_KEYS):
        idx = current_key_index % len(API_KEYS)
        key = API_KEYS[idx]
        # advance pointer for next call
        current_key_index = (idx + 1) % len(API_KEYS)
        if key not in exhausted_keys:
            return key
        attempts += 1
    # All keys exhausted
    raise RuntimeError("All configured API keys are exhausted. Please wait for quota reset or update keys.")

def mark_key_exhausted(api_key):
    """æ ‡è®°æŸä¸ª API key é…é¢å·²è€—å°½"""
    global exhausted_keys
    exhausted_keys.add(api_key)
    remaining = len(API_KEYS) - len(exhausted_keys)
    if remaining > 0:
        print(f"  âš ï¸  API Key é…é¢è€—å°½ï¼Œå‰©ä½™å¯ç”¨ keys: {remaining}/{len(API_KEYS)}")
    else:
        print("  âš ï¸  æ‰€æœ‰ API Keys é…é¢å·²è€—å°½ï¼å»ºè®®ç­‰å¾…é…é¢é‡ç½®æˆ–ä½¿ç”¨æ–°çš„ keys")


# --- 1. ä½¿ç”¨Pydanticå®šä¹‰ä¸¥æ ¼çš„JSONè¾“å‡ºç»“æ„ (Schema) ---
# ä¿®å¤ï¼šç§»é™¤æ‰€æœ‰ 'default' å‚æ•°ï¼Œå› ä¸ºGemini APIçš„åç«¯schemaè§£æå™¨ä¸å…¼å®¹å®ƒã€‚
class ProblemSchema(BaseModel):
    problem_id: int = Field(description="é—®é¢˜çš„å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œä¾‹å¦‚ 150")
    annotation: str = Field(description="æ ‡æ³¨ä¿¡æ¯ã€‚å¦‚æœæ²¡æœ‰ï¼Œåˆ™ä¸ºç©ºå­—ç¬¦ä¸²ã€‚")
    source: str = Field(description="é—®é¢˜çš„æ¥æºï¼Œé€šå¸¸ä¸º 'SolidGeo'ã€‚")
    problem_text_en: str = Field(description="é—®é¢˜çš„å®Œæ•´è‹±æ–‡è‡ªç„¶è¯­è¨€æè¿°ã€‚")
    construction_cdl: List[str] = Field(description="å®šä¹‰å‡ ä½•å®ä½“æ„é€ çš„è¾…åŠ©è°“è¯ï¼ŒåŒ…æ‹¬Shapeã€Collinearã€Cocircularã€Coplanarã€Cosphericalç­‰ã€‚ç”¨äºå®šä¹‰å½¢çŠ¶çš„è¾¹ã€çº¿æ®µå’Œç‚¹çš„å‡ ä½•å…³ç³»ã€‚")
    text_cdl: List[str] = Field(description="ä»…ä»ã€æ–‡æœ¬æè¿°ã€‘ä¸­æå–çš„å‡ ä½•å…³ç³»å’Œæ¡ä»¶ã€‚")
    image_cdl: List[str] = Field(description="ä»…ä»ã€å›¾ç‰‡ã€‘ä¸­æå–çš„å‡ ä½•å…³ç³»å’Œæ¡ä»¶ï¼ˆä¾‹å¦‚ç›´è§’ç¬¦å·ã€æ ‡æ³¨çš„é•¿åº¦ç­‰ï¼‰ã€‚")
    goal_cdl: str = Field(description="ä»é—®é¢˜çš„é—®å¥ä¸­æç‚¼å‡ºçš„æ±‚è§£ç›®æ ‡ï¼Œå¿…é¡»ä»¥ 'Value(...)' çš„å½¢å¼è¡¨ç¤ºã€‚")
    problem_answer: str = Field(description="é—®é¢˜çš„æ ‡å‡†ç­”æ¡ˆï¼Œå¿…é¡»æ˜¯çº¯æ•°å­—æˆ–æ•°å­¦è¡¨è¾¾å¼ï¼Œä¸å«ä»»ä½•å•ä½æˆ–æ–‡å­—ã€‚")
    problem_type: List[str] = Field(description="é—®é¢˜çš„ç±»å‹åˆ†ç±»ã€‚")
    complexity_level: str = Field(description="é—®é¢˜çš„å¤æ‚åº¦çº§åˆ«ã€‚")
    # ä¿®å¤ï¼šå°† List[Any] æ”¹ä¸º List[str]ï¼Œå°† Dict[str, Any] æ”¹ä¸º strï¼Œä»¥æ»¡è¶³APIå¯¹Schemaçš„ä¸¥æ ¼è¦æ±‚
    theorem_seqs: List[str] = Field(description="è§£å†³é—®é¢˜æ‰€éœ€çš„å®šç†åºåˆ—ï¼ˆå­—ç¬¦ä¸²åˆ—è¡¨ï¼‰ï¼Œé€šå¸¸ä¸ºç©ºåˆ—è¡¨ã€‚")
    theorem_seqs_dag: str = Field(description="ä¸€ä¸ªJSONå­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºè§£å†³é—®é¢˜æ‰€éœ€å®šç†çš„æœ‰å‘æ— ç¯å›¾ã€‚ä¾‹å¦‚ï¼š'{\"START\": []}'")

# --- 2. ä¼˜åŒ–åçš„é»„é‡‘æç¤ºè¯æ¨¡æ¿ ---
# å°†å…¶æ›´æ”¹ä¸ºæ¨¡æ¿ï¼Œä»¥ä¾¿åŠ¨æ€æ’å…¥è°“è¯åˆ—è¡¨
PROMPT_TEMPLATE = """
You are an expert in geometry, logic, and computer science. Your task is to precisely convert a geometry problem (with natural language and an image) into a JSON object following the provided JSON Schema.
You must strictly follow the schema and output a complete JSON object.

Rule 0: Predicate Compliance (MOST IMPORTANT)
- All CDL predicates you generate (e.g., `Equal`, `Cone`, `LengthOfLine`) MUST be strictly chosen from the official list below.
- Using any predicate that does not appear in this list is strictly forbidden.

--- Official Predicate List ---
{valid_predicates_str}
--- End of Official Predicate List ---

Core Rules and Constraints:

1) Information Source Separation:
   - `text_cdl` MUST include only facts extracted from the natural language description.
   - `image_cdl` MUST include only facts directly observable from the image (e.g., length labels, right-angle marks, shape recognition).
   - If a fact appears in both text and image, include it in both fields.

2) construction_cdl - Geometric construction predicates (IMPORTANT):
   `construction_cdl` defines basic construction for entities, and MUST include the following types where applicable:
   - Shape predicates: define edges/segments of shapes
     * For segments/edges: `Shape(AB,BC,CD,DA)` or `Shape(OP,PO)` or `Shape(PQ,QP)`
     * For points (spheres etc.): `Shape(O)` or `Shape(P)`
     * Example: rectangles require `Shape(AB,BC,CD,DA)`; cylinders require `Shape(PQ,QP)`
   - Collinearity/Cocircular/Coplanar/Cospherical:
     * `Collinear(PABQ)` - P, A, B, Q are collinear
     * `Cocircular(O)` - O is on a circle (for cone/cylinder base center)
     * `Cocircular(P)`, `Cocircular(Q)` - P and Q on their respective circles
     * `Coplanar(U,ABCD)` - U coplanar with ABCD
     * `Cospherical(O)` - O is on a sphere (for spheres)
   Important:
   - Carefully analyze the image to identify all necessary edges/segments/relations
   - Only return `[]` when no construction info is truly needed
   - Most problems require at least one `Shape(...)`
   - Cones/cylinders often need `Shape(...)` and `Cocircular(...)`
   - Spheres often need `Shape(O)` and `Cospherical(O)`
   - Cubes/prisms often need multiple `Shape(...)` with `Coplanar(...)`

3) Answer formatting:
   - `problem_answer` MUST be a pure number or expression (e.g., "10", "254.47", "36*pi"), and MUST NOT contain units or extra text.

4) Core predicate logic:
   - Length/Height/Generator: `Equal(LengthOfLine(A,B),5)`, `Equal(HeightOfCone(O,P),12)`, `Equal(BusbarOfCone(O,P),13)`
   - Radius/Diameter: `Equal(RadiusOfCircle(O),5)`, `Value(DiameterOfCircle(O))`
   - Relations: `PerpendicularBetweenLine(A,B,C,D)`, `ParallelBetweenLine(A,B,C,D)`
   - Goal: the requested quantity MUST be wrapped by `Value(...)`.

5) Predicate and Operator Legality (CRITICAL):
   - Only reuse names from the official predicate list; DO NOT invent new construction predicates (e.g., `Triangle`, `Line`, `Angle` are FORBIDDEN).
   - Quantities allowed in CDL expressions (including `goal_cdl`) are LIMITED to:
     `VolumeOfCone`, `VolumeOfCylinder`, `VolumeOfSphere`, `VolumeOfCuboid`, `VolumeOfQuadrangularPyramid`,
     `SurfaceAreaOfCylinder`, `SurfaceAreaOfCuboid`, `SurfaceAreaOfQuadrangularPrism`, `SurfaceAreaOfQuadrangularPyramid`,
     `LateralareaOfCone`, `LateralareaOfCylinder`, `AreaOfCircle`, `AreaOfSphere`, `AreaOfCuboid`, `AreaOfQuadrilateral`,
     `PerimeterOfQuadrilateral`, `DiameterOfCircle`, `RadiusOfCircle`, `LengthOfLine`, `HeightOfCone`, `HeightOfCylinder`, `BusbarOfCone`.
     If a problem mentions other quantities, rewrite them using these standard quantities or include supporting info in `text_cdl/image_cdl` and then use the standard quantities.
   - Only the following algebraic operators are allowed: `Value`, `Add`, `Sub`, `Mul`, `Div`. For "1/2 Ã— X", write `Mul(1/2,X)`.
   - Formatting: NO extra spaces inside any predicate/operator. Use `Add(A,B,C)` and `Equal(HeightOfCylinder(P,Q),2)`, NOT `Add(A, B)` or `Equal(..., 2)`. Also avoid leading/trailing spaces in names (e.g., never `" VolumeOfCylinder"`).

6) Completeness Checks:
   - Ensure every entity used by `text_cdl`/`image_cdl` exists in `construction_cdl`
   - Ensure the target entity in `goal_cdl` exists in the construction as well
   - Self-check after generation: verify all predicates/operators are allowed, no extra spaces, and no undeclared entities are referenced.

Important: Output Requirements
1. You MUST output a complete JSON object with all required fields
2. All CDL fields MUST be arrays of strings (e.g., `["Cylinder(O,P)", "Equal(HeightOfCylinder(O,P),12)"]`)
3. `goal_cdl` MUST be a string (e.g., `"Value(VolumeOfCone(O,P))"`)
4. Required fields:
   - `problem_id`: integer
   - `annotation`: string (can be empty)
   - `source`: string (usually "SolidGeo")
   - `problem_text_en`: string
   - `construction_cdl`: array of strings
   - `text_cdl`: array of strings
   - `image_cdl`: array of strings
   - `goal_cdl`: string
   - `problem_answer`: string
   - `problem_type`: array of strings
   - `complexity_level`: string
   - `theorem_seqs`: array of strings (can be empty)
   - `theorem_seqs_dag`: JSON string (e.g., '{{"START": []}}')

Output Example:
Please follow the JSON example below (ALL fields are required):

JSON_EXAMPLE_PLACEHOLDER

Ensure the JSON is complete and properly formatted. Do NOT truncate or omit any fields.
"""

# JSONç¤ºä¾‹ï¼ˆå•ç‹¬å®šä¹‰ï¼Œé¿å…format()è§£æé—®é¢˜ï¼‰
JSON_EXAMPLE = """```json
{
  "problem_id": 1,
  "annotation": "",
  "source": "SolidGeo",
  "problem_text_en": "Find the volume of the cone.",
  "construction_cdl": ["Shape(OP,PO)", "Cocircular(O)"],
  "text_cdl": ["Equal(HeightOfCone(O,P),12)"],
  "image_cdl": ["Cone(O,P)", "Equal(BusbarOfCone(O,P),13)"],
  "goal_cdl": "Value(VolumeOfCone(O,P))",
  "problem_answer": "10",
  "problem_type": ["Solid Geometry"],
  "complexity_level": "Level 1",
  "theorem_seqs": [],
  "theorem_seqs_dag": "{\"START\": []}"
}
```"""

def load_few_shot_examples(train_dir, images_dir, max_examples=40):
    """
    ä»è®­ç»ƒé›†ç›®å½•åŠ è½½few-shotèŒƒä¾‹ï¼Œå¹¶åŠ è½½å¯¹åº”çš„å›¾ç‰‡
    
    Args:
        train_dir: è®­ç»ƒèŒƒä¾‹ç›®å½•
        images_dir: å›¾ç‰‡ç›®å½•
        max_examples: æœ€å¤§èŒƒä¾‹æ•°é‡ï¼ˆé»˜è®¤40ä¸ªï¼‰
    
    Returns:
        examples_data: List[Dict] åŒ…å«èŒƒä¾‹æ•°æ®çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«æ–‡æœ¬ã€å›¾ç‰‡base64å’ŒCDL
        valid_count: int æœ‰æ•ˆèŒƒä¾‹æ•°é‡
    """
    examples_data = []
    valid_count = 0
    
    try:
        # è·å–æ‰€æœ‰JSONæ–‡ä»¶å¹¶æ’åº
        train_json_files = [
            f for f in os.listdir(train_dir)
            if f.endswith('.json') and os.path.isfile(os.path.join(train_dir, f))
        ]
        train_json_files.sort(key=lambda x: int(x.split('.')[0]) if x.split('.')[0].isdigit() else 999999)
        
        for json_file in train_json_files:
            if valid_count >= max_examples:
                break
                
            problem_id = json_file.split('.')[0]
            json_path = os.path.join(train_dir, json_file)
            
            try:
                with open(json_path, 'r', encoding='utf-8') as f:
                    train_data = json.load(f)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„CDLæ•°æ®
                has_valid_cdl = False
                cdl_fields = ['construction_cdl', 'text_cdl', 'image_cdl', 'goal_cdl']
                for field in cdl_fields:
                    val = train_data.get(field, [])
                    if (isinstance(val, list) and len(val) > 0) or (isinstance(val, str) and val.strip()):
                        has_valid_cdl = True
                        break
                
                if not has_valid_cdl:
                    continue
                
                # è·å–é—®é¢˜æ–‡æœ¬
                problem_text = train_data.get('problem_text_en', '').strip()
                if not problem_text:
                    # å°è¯•ä»txtæ–‡ä»¶è¯»å–
                    txt_path = os.path.join(train_dir, f"{problem_id}.txt")
                    if os.path.exists(txt_path):
                        with open(txt_path, 'r', encoding='utf-8') as f:
                            problem_text = f.read().strip()
                
                # è·å–å›¾ç‰‡å¹¶ç¼–ç ä¸ºbase64
                img_base64 = None
                image_extensions = ['.png', '.jpg', '.jpeg']
                for ext in image_extensions:
                    candidate_path = os.path.join(images_dir, f"{problem_id}{ext}")
                    if os.path.exists(candidate_path):
                        img_base64 = image_to_base64(candidate_path)
                        break
                
                # æ„å»ºèŒƒä¾‹æ•°æ®
                example_data = {
                    "problem_id": problem_id,
                    "problem_text": problem_text if problem_text else "æ— æ–‡æœ¬ä¿¡æ¯",
                    "image_base64": img_base64,
                    "text_cdl": train_data.get('text_cdl', []),
                    "image_cdl": train_data.get('image_cdl', []),
                    "construction_cdl": train_data.get('construction_cdl', []),
                    "goal_cdl": train_data.get('goal_cdl', ''),
                    "problem_answer": train_data.get('problem_answer', '')
                }
                
                examples_data.append(example_data)
                valid_count += 1
                
            except Exception as e:
                print(f"è·³è¿‡è®­ç»ƒæ ·æœ¬{problem_id}ï¼ˆåŠ è½½å¤±è´¥ï¼‰: {str(e)}")
                continue
        
        print(f"æˆåŠŸåŠ è½½ {valid_count} ä¸ªè®­ç»ƒèŒƒä¾‹ï¼ˆåŒ…å«å›¾ç‰‡ï¼‰")
        
    except Exception as e:
        print(f"åŠ è½½è®­ç»ƒèŒƒä¾‹æ—¶å‡ºé”™: {e}")
        return [], 0
        
    return examples_data, valid_count

def load_valid_predicates(gdl_path):
    """ä» predicate_GDL.json æ–‡ä»¶ä¸­åŠ è½½æ‰€æœ‰åˆæ³•çš„è°“è¯åç§°ã€‚"""
    try:
        with open(gdl_path, 'r', encoding='utf-8') as f:
            gdl_data = json.load(f)
        
        predicate_names = set()
        
        # æå– "Entity", "Relation", "Attribution" ä¸­çš„æ‰€æœ‰è°“è¯
        for category in ["Entity", "Relation", "Attribution"]:
            if category in gdl_data:
                for key in gdl_data[category].keys():
                    predicate_name = key.split('(')[0]
                    predicate_names.add(predicate_name)
                    
        # ä¹Ÿæ·»åŠ ä¸€äº›å¯èƒ½çš„åŸºç¡€å®ä½“è°“è¯
        for preset_key in ["BasicEntity", "Construction"]:
            if preset_key in gdl_data.get("Preset", {}):
                for name in gdl_data["Preset"][preset_key]:
                    predicate_names.add(name)
        
        # æ·»åŠ  Equal å’Œ Value è°“è¯
        predicate_names.add("Equal")
        predicate_names.add("Value")

        return sorted(predicate_names)
    except Exception as e:
        print(f"é”™è¯¯: æ— æ³•åŠ è½½æˆ–è§£æè°“è¯åº“ '{gdl_path}': {e}")
        return None

def fix_incomplete_json(json_str):
    """å°è¯•ä¿®å¤ä¸å®Œæ•´çš„JSONå­—ç¬¦ä¸²"""
    try:
        # å°è¯•ç›´æ¥è§£æ
        return json.loads(json_str)
    except json.JSONDecodeError:
        pass
    
    # å°è¯•ä¿®å¤å¸¸è§çš„JSONæˆªæ–­é—®é¢˜
    fixed_str = json_str.strip()
    
    # å¦‚æœä»¥ { å¼€å¤´ä½†æ²¡æœ‰ }ï¼Œå°è¯•æ·»åŠ 
    if fixed_str.startswith('{') and not fixed_str.rstrip().endswith('}'):
        # æ‰¾åˆ°æœ€åä¸€ä¸ªå®Œæ•´çš„é”®å€¼å¯¹
        last_comma = fixed_str.rfind(',')
        if last_comma > 0:
            # ç§»é™¤æœ€åä¸€ä¸ªä¸å®Œæ•´çš„é”®å€¼å¯¹
            fixed_str = fixed_str[:last_comma] + '}'
        else:
            fixed_str = fixed_str + '}'
    
    # å°è¯•è§£æä¿®å¤åçš„å­—ç¬¦ä¸²
    try:
        return json.loads(fixed_str)
    except json.JSONDecodeError:
        return None

def normalize_api_response(data, problem_id, problem_text_en):
    """è§„èŒƒåŒ–APIè¿”å›çš„æ•°æ®ï¼Œå¡«å……ç¼ºå¤±å­—æ®µå¹¶ä¿®æ­£æ ¼å¼"""
    normalized = {}
    
    # å¿…éœ€å­—æ®µçš„é»˜è®¤å€¼
    normalized['problem_id'] = data.get('problem_id') or problem_id
    normalized['annotation'] = data.get('annotation') or ''
    normalized['source'] = data.get('source') or 'SolidGeo'
    normalized['problem_text_en'] = data.get('problem_text_en') or data.get('problem_text') or problem_text_en
    normalized['problem_answer'] = data.get('problem_answer') or ''
    normalized['problem_type'] = data.get('problem_type') or []
    normalized['complexity_level'] = data.get('complexity_level') or ''
    normalized['theorem_seqs'] = data.get('theorem_seqs') or []
    normalized['theorem_seqs_dag'] = data.get('theorem_seqs_dag') or '{"START": []}'
    
    # å¤„ç†CDLå­—æ®µ - ç¡®ä¿å®ƒä»¬æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨
    def normalize_cdl_list(cdl_data):
        if cdl_data is None:
            return []
        if isinstance(cdl_data, list):
            result = []
            for item in cdl_data:
                if isinstance(item, str):
                    result.append(item)
                elif isinstance(item, dict):
                    # å°è¯•ä»å­—å…¸ä¸­æå–è°“è¯å­—ç¬¦ä¸²
                    # ä¾‹å¦‚: {"predicate": "Cylinder", "params": ["O", "P"]} -> "Cylinder(O,P)"
                    predicate = item.get('predicate') or list(item.keys())[0] if item else None
                    if predicate:
                        params = item.get('params') or item.get(predicate) or []
                        if isinstance(params, list):
                            params_str = ','.join(str(p) for p in params)
                            result.append(f"{predicate}({params_str})")
                        else:
                            result.append(str(predicate))
            return result
        return []
    
    normalized['construction_cdl'] = normalize_cdl_list(
        data.get('construction_cdl')
    )
    normalized['text_cdl'] = normalize_cdl_list(
        data.get('text_cdl')
    )
    normalized['image_cdl'] = normalize_cdl_list(
        data.get('image_cdl')
    )
    
    # å¤„ç†goal_cdl - ç¡®ä¿å®ƒæ˜¯å­—ç¬¦ä¸²
    goal_cdl = data.get('goal_cdl')
    if isinstance(goal_cdl, list) and goal_cdl:
        normalized['goal_cdl'] = goal_cdl[0] if isinstance(goal_cdl[0], str) else str(goal_cdl[0])
    elif isinstance(goal_cdl, str):
        normalized['goal_cdl'] = goal_cdl
    else:
        normalized['goal_cdl'] = ''
    
    # å¤„ç†åµŒå¥—çš„cdlç»“æ„ï¼ˆå¦‚ {"cdl": {"construction_cdl": [...]}}ï¼‰
    if 'cdl' in data and isinstance(data['cdl'], dict):
        cdl_data = data['cdl']
        if 'construction_cdl' in cdl_data:
            normalized['construction_cdl'] = normalize_cdl_list(cdl_data['construction_cdl'])
        if 'text_cdl' in cdl_data:
            normalized['text_cdl'] = normalize_cdl_list(cdl_data['text_cdl'])
        if 'image_cdl' in cdl_data:
            normalized['image_cdl'] = normalize_cdl_list(cdl_data['image_cdl'])
        if 'goal_cdl' in cdl_data:
            goal = cdl_data['goal_cdl']
            if isinstance(goal, list) and goal:
                normalized['goal_cdl'] = goal[0] if isinstance(goal[0], str) else str(goal[0])
            elif isinstance(goal, str):
                normalized['goal_cdl'] = goal
    
    return normalized

def image_to_base64(image_path):
    """å°†å›¾ç‰‡è½¬æ¢ä¸ºbase64ç¼–ç ï¼ˆå‚è€ƒ test_gemini_problems.pyï¼‰"""
    try:
        with PIL.Image.open(image_path) as img:
            # å¦‚æœå›¾ç‰‡å¤ªå¤§ï¼Œè°ƒæ•´å¤§å°ä»¥èŠ‚çœAPIæˆæœ¬
            max_size = (1024, 1024)
            img.thumbnail(max_size, PIL.Image.Resampling.LANCZOS)
            
            # è½¬æ¢ä¸ºRGBï¼ˆå¦‚æœæ˜¯RGBAæˆ–å…¶ä»–æ ¼å¼ï¼‰
            if img.mode != 'RGB':
                img = img.convert('RGB')
            
            # ä¿å­˜åˆ°å†…å­˜ç¼“å†²åŒº
            buffered = BytesIO()
            img.save(buffered, format="JPEG", quality=85)
            
            # ç¼–ç ä¸ºbase64
            img_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')
            return f"data:image/jpeg;base64,{img_base64}"
    except Exception as e:
        print(f"  âš ï¸  å›¾ç‰‡è½¬æ¢å¤±è´¥: {e}")
        return None

def generate_geometry_json(problem_text, image_path, golden_prompt, problem_id, few_shot_examples_data=None, retries=5, delay=3):
    """
    é€šè¿‡ aicanapi.com è°ƒç”¨ Gemini API ç”Ÿæˆå•ä¸ªå‡ ä½•é—®é¢˜çš„JSONï¼Œä½¿ç”¨JSON Schemaå¼ºåˆ¶ç»“æ„åŒ–è¾“å‡ºã€‚
    
    Args:
        problem_text: é—®é¢˜æ–‡æœ¬ï¼ˆå¯ä»¥ä¸ºç©ºï¼‰
        image_path: é—®é¢˜å›¾ç‰‡è·¯å¾„ï¼ˆå¯ä»¥ä¸ºNoneï¼Œè¡¨ç¤ºæ²¡æœ‰å›¾ç‰‡ï¼‰
        golden_prompt: åŸºç¡€æç¤ºè¯
        problem_id: é—®é¢˜ID
        few_shot_examples_data: Few-shotèŒƒä¾‹æ•°æ®åˆ—è¡¨ï¼ˆåŒ…å«å›¾ç‰‡ï¼‰
        retries: é‡è¯•æ¬¡æ•°
        delay: é‡è¯•å»¶è¿Ÿ
    """
    # å‡†å¤‡å›¾ç‰‡ï¼ˆå¦‚æœæä¾›ï¼‰
    image_base64 = None
    if image_path:
        print(f"    ğŸ–¼ï¸  æ­£åœ¨å¤„ç†å›¾ç‰‡: {os.path.basename(image_path)}")
        image_base64 = image_to_base64(image_path)
        if not image_base64:
            print(f"    âš ï¸  è­¦å‘Š: æ— æ³•åŠ è½½å›¾ç‰‡ {image_path}ï¼Œå°†ä»…ä½¿ç”¨æ–‡æœ¬å¤„ç†ã€‚")
        else:
            print("    âœ… å›¾ç‰‡å¤„ç†å®Œæˆ")
    else:
        print("    â„¹ï¸  æœªæä¾›å›¾ç‰‡ï¼Œå°†ä»…ä½¿ç”¨æ–‡æœ¬å¤„ç†ã€‚")
    
    # æ„å»ºæ¶ˆæ¯ - åŒ…å«few-shotèŒƒä¾‹
    messages = []
    
    # System messageåŒ…å«åŸºç¡€æç¤ºè¯
    messages.append({
        "role": "system",
        "content": golden_prompt + "\n\nIMPORTANT: Your JSON output must include all required fields and strictly follow the format above."
    })
    
    # æ·»åŠ few-shotèŒƒä¾‹ï¼ˆå¦‚æœæä¾›ï¼‰
    if few_shot_examples_data:
        for i, example in enumerate(few_shot_examples_data, 1):
            # èŒƒä¾‹çš„user message
            example_content = [
                {
                    "type": "text",
                    "text": f"Example {i} (ID: {example['problem_id']}):\nNatural Language Description: \"{example['problem_text']}\"\n\nPlease analyze the image and text, then generate the CDL fields in JSON format."
                }
            ]
            
            # å¦‚æœèŒƒä¾‹æœ‰å›¾ç‰‡ï¼Œæ·»åŠ åˆ°æ¶ˆæ¯ä¸­
            if example.get('image_base64'):
                example_content.append({
                    "type": "image_url",
                    "image_url": {
                        "url": example['image_base64']
                    }
                })
            
            messages.append({
                "role": "user",
                "content": example_content
            })
            
            # èŒƒä¾‹çš„assistantå›å¤ï¼ˆåŒ…å«CDLè¾“å‡ºï¼‰
            messages.append({
                "role": "assistant",
                "content": json.dumps({
                    "construction_cdl": example['construction_cdl'],
                    "text_cdl": example['text_cdl'],
                    "image_cdl": example['image_cdl'],
                    "goal_cdl": example['goal_cdl'],
                    "problem_answer": example['problem_answer']
                }, ensure_ascii=False)
            })
    
    # å½“å‰é—®é¢˜çš„user message
    user_content = [
        {
            "type": "text",
            "text": f"Now process this problem (ID: {problem_id}):\nNatural Language Description: \"{problem_text if problem_text else '(No text description, analyze the image only)'}\"\n\nPlease analyze the image and text, then generate a complete JSON output including all required fields."
        }
    ]
    
    # å¦‚æœæœ‰å›¾ç‰‡ï¼Œæ·»åŠ åˆ°æ¶ˆæ¯ä¸­
    if image_base64:
        user_content.append({
            "type": "image_url",
            "image_url": {
                "url": image_base64
            }
        })
    
    messages.append({
        "role": "user",
        "content": user_content
    })
    
    # å¦‚æœæ²¡æœ‰å›¾ç‰‡ä¹Ÿæ²¡æœ‰æ–‡æœ¬ï¼Œè¿”å›é”™è¯¯
    if not image_base64 and not problem_text:
        return {"status": "error", "message": "é—®é¢˜æ—¢æ²¡æœ‰å›¾ç‰‡ä¹Ÿæ²¡æœ‰æ–‡æœ¬ï¼Œæ— æ³•å¤„ç†", "problem_text": problem_text}
    
    consecutive_quota_errors = 0
    
    for attempt in range(retries):
        try:
            # è·å–ä¸‹ä¸€ä¸ª API key
            api_key = get_next_api_key()
            
            if attempt > 0:
                print(f"    ğŸ”„ é‡è¯•ç¬¬ {attempt + 1} æ¬¡...")
            
            # åˆ›å»º OpenAI å…¼å®¹å®¢æˆ·ç«¯ï¼ˆé€šè¿‡ aicanapi.comï¼‰
            client = openai.OpenAI(
                api_key=api_key,
                base_url=GEMINI_API_BASE
            )
            
            # è°ƒç”¨ APIï¼ˆä½¿ç”¨ Gemini æ¨¡å‹åç§°ï¼‰
            # æ³¨æ„ï¼šOpenAI å…¼å®¹ API å¯èƒ½ä¸æ”¯æŒ response_formatï¼Œæˆ‘ä»¬éœ€è¦åœ¨æç¤ºè¯ä¸­å¼ºè°ƒ JSON æ ¼å¼
            print(f"    â³ å‘é€APIè¯·æ±‚åˆ° {GEMINI_MODEL}...")
            print(f"    â„¹ï¸  è¯·æ±‚åŒ…å« {len(messages)} æ¡æ¶ˆæ¯ï¼Œå…¶ä¸­ {len(few_shot_examples_data) if few_shot_examples_data else 0} ä¸ª few-shot èŒƒä¾‹")
            
            # è®¾ç½®socketè¶…æ—¶ï¼ˆ120ç§’ï¼‰
            old_timeout = socket.getdefaulttimeout()
            socket.setdefaulttimeout(120)
            
            try:
                response = client.chat.completions.create(
                    model=GEMINI_MODEL,
                    messages=messages,
                    max_tokens=16
                    000,  # å¢åŠ  token é™åˆ¶ä»¥æ”¯æŒå®Œæ•´çš„ JSON è¾“å‡ºï¼ˆAPIæœ€å¤§æ”¯æŒ65536ï¼‰
                    temperature=0.1,
                    timeout=120.0  # 120ç§’è¶…æ—¶
                )
                print("    ğŸ“¥ æ”¶åˆ°APIå“åº”")
            except Exception as api_error:
                error_msg = f"APIè°ƒç”¨å¤±è´¥: {str(api_error)}"
                print(f"    âŒ {error_msg}")
                # æ¢å¤åŸæ¥çš„è¶…æ—¶è®¾ç½®
                socket.setdefaulttimeout(old_timeout)
                if attempt == retries - 1:
                    return {"status": "error", "message": error_msg, "problem_text": problem_text}
                continue
            finally:
                # æ¢å¤åŸæ¥çš„è¶…æ—¶è®¾ç½®
                socket.setdefaulttimeout(old_timeout)
            
            response_text = ""
            if isinstance(response, str):
                response_text = response.strip()
            elif hasattr(response, 'choices') and response.choices and response.choices[0].message.content:
                response_text = response.choices[0].message.content.strip()

            if response_text:
                # Debug: æ˜¾ç¤ºå“åº”çš„å‰500å­—ç¬¦ä»¥ä¾¿ç›‘æ§
                print(f"    ğŸ’¬ APIå“åº”é¢„è§ˆ: {response_text[:200]}...")
                
                # å°è¯•æå– JSONï¼ˆå¯èƒ½åŒ…å« markdown ä»£ç å—ï¼‰
                # ç§»é™¤å¯èƒ½çš„ markdown ä»£ç å—æ ‡è®°
                if response_text.startswith("```json"):
                    response_text = response_text[7:]  # ç§»é™¤ ```json
                if response_text.startswith("```"):
                    response_text = response_text[3:]  # ç§»é™¤ ```
                if response_text.endswith("```"):
                    response_text = response_text[:-3]  # ç§»é™¤ç»“å°¾çš„ ```
                response_text = response_text.strip()
                
                try:
                    # å°è¯•è§£æJSONï¼ˆå¯èƒ½ä¸å®Œæ•´ï¼‰
                    parsed_data = json.loads(response_text)
                except json.JSONDecodeError:
                    # å°è¯•ä¿®å¤ä¸å®Œæ•´çš„JSON
                    print("    ğŸ”§ å°è¯•ä¿®å¤ä¸å®Œæ•´çš„JSON...")
                    parsed_data = fix_incomplete_json(response_text)
                    if parsed_data is None:
                        error_message = f"JSONè§£æå¤±è´¥ä¸”æ— æ³•ä¿®å¤ (å°è¯• {attempt + 1}/{retries})\nåŸå§‹å“åº”: {response_text[:500]}"
                        print(f"é”™è¯¯/è­¦å‘Š: {error_message}")
                        if attempt == retries - 1:
                            return {"status": "error", "message": error_message, "raw_output": response_text, "problem_text": problem_text}
                        continue
                
                # è§„èŒƒåŒ–æ•°æ®æ ¼å¼
                print("    ğŸ”„ è§„èŒƒåŒ–æ•°æ®æ ¼å¼...")
                # å°è¯•ä»è§£æçš„æ•°æ®ä¸­è·å–problem_id
                api_problem_id = parsed_data.get('problem_id')
                if api_problem_id:
                    try:
                        api_problem_id = int(api_problem_id)
                    except (ValueError, TypeError):
                        api_problem_id = None
                normalized_data = normalize_api_response(parsed_data, api_problem_id, problem_text)
                
                try:
                    # ä½¿ç”¨Pydanticæ¨¡å‹éªŒè¯æ•°æ®
                    validated_data = ProblemSchema(**normalized_data)
                    # å°†éªŒè¯åçš„Pydanticæ¨¡å‹è½¬æ¢ä¸ºå­—å…¸ä»¥ä¾¿ä¿å­˜
                    return {"status": "success", "data": validated_data.dict(), "problem_text": problem_text}
                except Exception as e:
                    error_message = f"æ•°æ®éªŒè¯å¤±è´¥ (å°è¯• {attempt + 1}/{retries}): {e}\nè§„èŒƒåŒ–åçš„æ•°æ®: {json.dumps(normalized_data, ensure_ascii=False)[:500]}"
                    print(f"é”™è¯¯/è­¦å‘Š: {error_message}")
                    if attempt == retries - 1:
                        return {"status": "error", "message": error_message, "raw_output": response_text, "normalized_data": normalized_data, "problem_text": problem_text}
            else:
                raise ValueError("APIè¿”å›å†…å®¹ä¸ºç©ºã€‚")

        except Exception as e:
            error_str = str(e)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯é…é¢è€—å°½é”™è¯¯
            if "429" in error_str or "quota" in error_str.lower() or "exhausted" in error_str.lower():
                mark_key_exhausted(api_key)
                consecutive_quota_errors += 1
                
                # å¦‚æœè¿ç»­å¤šæ¬¡é…é¢é”™è¯¯ï¼Œå¢åŠ ç­‰å¾…æ—¶é—´
                if consecutive_quota_errors >= 3:
                    wait_time = 30  # ç­‰å¾…30ç§’
                    print(f"  â³ é…é¢å—é™ï¼Œç­‰å¾… {wait_time} ç§’åç»§ç»­...")
                    time.sleep(wait_time)
                    consecutive_quota_errors = 0
                else:
                    time.sleep(delay)
            else:
                # å…¶ä»–ç±»å‹çš„é”™è¯¯
                error_message = f"APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt + 1}/{retries}): {e}"
                print(f"  âš ï¸  {error_message}")
                time.sleep(delay)
            
            if attempt == retries - 1:
                return {"status": "error", "message": f"å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°: {error_str}", "problem_text": problem_text}
        
        time.sleep(delay)

    return {"status": "error", "message": "å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°", "problem_text": problem_text}


def batch_process_problems(input_dir, output_dir, example_dir, gdl_path, start_id=1, end_id=None, force_regenerate=False):
    """
    æ‰¹é‡å¤„ç†æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰é—®é¢˜ã€‚
    æ–°æµç¨‹ï¼šè¾“å…¥æ–‡ä»¶å¤¹åŒ…å«éƒ¨åˆ†å¡«å……çš„ .json æ–‡ä»¶ã€‚
    
    Args:
        input_dir: è¾“å…¥ç›®å½•
        output_dir: è¾“å‡ºç›®å½•
        example_dir: èŒƒä¾‹ç›®å½•
        gdl_path: è°“è¯å®šä¹‰æ–‡ä»¶è·¯å¾„
        start_id: èµ·å§‹é—®é¢˜IDï¼ˆåŒ…å«ï¼‰ï¼Œé»˜è®¤1
        end_id: ç»“æŸé—®é¢˜IDï¼ˆåŒ…å«ï¼‰ï¼Œé»˜è®¤Noneè¡¨ç¤ºä¸é™åˆ¶
        force_regenerate: æ˜¯å¦å¼ºåˆ¶é‡æ–°ç”Ÿæˆæ‰€æœ‰é—®é¢˜ï¼ˆå¿½ç•¥å·²å¤„ç†çš„æ ‡è®°ï¼‰ï¼Œé»˜è®¤False
    """
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # ä»GDLæ–‡ä»¶åŠ è½½åˆæ³•çš„è°“è¯
    valid_predicates = load_valid_predicates(gdl_path)
    if not valid_predicates:
        print("ç”±äºæ— æ³•åŠ è½½è°“è¯åº“ï¼Œå¤„ç†ä¸­æ­¢ã€‚")
        return
    
    # å°†è°“è¯åˆ—è¡¨æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²ï¼Œä»¥ä¾¿æ³¨å…¥æç¤º
    valid_predicates_str = ", ".join(valid_predicates)

    # ä»è®­ç»ƒé›†åŠ è½½few-shotèŒƒä¾‹ï¼ˆåŒ…å«å›¾ç‰‡ï¼‰
    train_dir = example_dir  # example_dirç°åœ¨æŒ‡å‘è®­ç»ƒé›†ç›®å½•
    images_dir = "src/fgps/formalgeo7k_v2/images"  # å›¾ç‰‡ç›®å½•
    # ä½¿ç”¨10ä¸ªfew-shotæ ·æœ¬ï¼ˆå‡å°‘ä»¥èŠ‚çœè¾“å…¥tokenç©ºé—´ï¼‰
    few_shot_examples_data, example_count = load_few_shot_examples(train_dir, images_dir, max_examples=10)
    
    if example_count == 0:
        print("è­¦å‘Š: æœªèƒ½åŠ è½½ few-shot èŒƒä¾‹ï¼Œå°†ç»§ç»­ä½¿ç”¨æ— èŒƒä¾‹çš„æç¤ºè¯ã€‚")
    
    # æ„å»ºèŒƒä¾‹æ–‡æœ¬ï¼ˆç”¨äºæç¤ºè¯ï¼Œè‹±æ–‡ï¼‰
    examples_text = ""
    for i, example in enumerate(few_shot_examples_data, 1):
        img_note = f"Image: {example['problem_id']}.png" if example['image_base64'] else "No image"
        examples_text += f"""
#### Example {i} (ID: {example['problem_id']})
- problem_text: {example['problem_text']}
- {img_note}
- text_cdl: {example['text_cdl']}
- image_cdl: {example['image_cdl']}
- construction_cdl: {example['construction_cdl']}
- goal_cdl: {example['goal_cdl']}
- problem_answer: {example['problem_answer']}
"""
    
    # åŠ¨æ€æ„å»ºé»„é‡‘æç¤ºè¯
    golden_prompt = PROMPT_TEMPLATE.format(valid_predicates_str=valid_predicates_str)
    # æ›¿æ¢JSONç¤ºä¾‹å ä½ç¬¦
    golden_prompt = golden_prompt.replace("JSON_EXAMPLE_PLACEHOLDER", JSON_EXAMPLE)
    if examples_text:
        golden_prompt += "\n--- Here are several high-quality examples. STRICTLY follow their format and logic. ---\n"
        golden_prompt += examples_text
    
    # 1. ä¿®æ”¹ï¼šæŸ¥æ‰¾ .json æ–‡ä»¶è€Œä¸æ˜¯ .txt æ–‡ä»¶
    problem_files = [f for f in os.listdir(input_dir) if f.endswith('.json')]
    
    # è¿‡æ»¤é—®é¢˜IDèŒƒå›´
    filtered_files = []
    for json_filename in problem_files:
        try:
            problem_id = int(json_filename.split('.')[0])
            if problem_id >= start_id and (end_id is None or problem_id <= end_id):
                filtered_files.append(json_filename)
        except ValueError:
            # å¦‚æœæ— æ³•è§£æIDï¼Œè·³è¿‡è¯¥æ–‡ä»¶
            continue
    
    filtered_files.sort(key=lambda x: int(x.split('.')[0]))
    
    # æ–­ç‚¹ç»­ä¼ ï¼šåŠ è½½å·²æœ‰çš„æ—¥å¿—æ–‡ä»¶ï¼Œæ£€æŸ¥å·²å¤„ç†çš„é—®é¢˜
    log_file_path = os.path.join(output_dir, "_generation_log.json")
    processed_problems = set()  # å·²æˆåŠŸå¤„ç†çš„é—®é¢˜IDé›†åˆ
    log_data = []  # æ—¥å¿—æ•°æ®
    
    # å¦‚æœå¼ºåˆ¶é‡æ–°ç”Ÿæˆï¼Œè·³è¿‡åŠ è½½å·²å¤„ç†çš„é—®é¢˜
    if force_regenerate:
        print("ğŸ”„ å¼ºåˆ¶é‡æ–°ç”Ÿæˆæ¨¡å¼ï¼šå°†é‡æ–°ç”Ÿæˆæ‰€æœ‰é—®é¢˜ï¼Œå¿½ç•¥å·²å­˜åœ¨çš„è¾“å‡ºã€‚")
        # å¯ä»¥é€‰æ‹©å¤‡ä»½æ—§çš„æ—¥å¿—æ–‡ä»¶
        if os.path.exists(log_file_path):
            backup_path = log_file_path + ".backup"
            try:
                import shutil
                shutil.copy2(log_file_path, backup_path)
                print(f"ğŸ“¦ å·²å¤‡ä»½ç°æœ‰æ—¥å¿—åˆ°: {backup_path}")
            except Exception as e:
                print(f"âš ï¸  è­¦å‘Š: å¤‡ä»½æ—¥å¿—æ–‡ä»¶å¤±è´¥: {e}")
    else:
        # æ­£å¸¸æ¨¡å¼ï¼šåŠ è½½å·²å¤„ç†çš„é—®é¢˜
        if os.path.exists(log_file_path):
            try:
                with open(log_file_path, 'r', encoding='utf-8') as f:
                    existing_logs = json.load(f)
                # æ‰¾å‡ºå·²æˆåŠŸå¤„ç†çš„é—®é¢˜
                for log_entry in existing_logs:
                    if log_entry.get("status") == "success":
                        processed_problems.add(str(log_entry.get("problem_id")))
                log_data = existing_logs  # ä¿ç•™å·²æœ‰æ—¥å¿—
                print(f"ğŸ“‹ åŠ è½½å·²æœ‰æ—¥å¿—: æ‰¾åˆ° {len(processed_problems)} ä¸ªå·²æˆåŠŸå¤„ç†çš„é—®é¢˜ï¼Œå°†ä»æ–­ç‚¹ç»§ç»­...")
            except Exception as e:
                print(f"âš ï¸  è­¦å‘Š: æ— æ³•åŠ è½½å·²æœ‰æ—¥å¿—æ–‡ä»¶ '{log_file_path}': {e}ï¼Œå°†ä»å¤´å¼€å§‹å¤„ç†ã€‚")
        
        # æ£€æŸ¥è¾“å‡ºç›®å½•ä¸­å·²å­˜åœ¨çš„æ–‡ä»¶ï¼ˆå³ä½¿æ—¥å¿—ä¸­æ²¡æœ‰è®°å½•ï¼‰
        if os.path.exists(output_dir):
            existing_output_files = [f for f in os.listdir(output_dir) if f.endswith('.json') and f != '_generation_log.json']
            for output_file in existing_output_files:
                problem_id_from_file = output_file.split('.')[0]
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆï¼ˆåŒ…å«å¿…è¦å­—æ®µï¼‰
                output_file_path = os.path.join(output_dir, output_file)
                try:
                    with open(output_file_path, 'r', encoding='utf-8') as f:
                        output_data = json.load(f)
                    # å¦‚æœæ–‡ä»¶åŒ…å«problem_idå­—æ®µï¼Œè®¤ä¸ºå·²å¤„ç†ï¼ˆéœ€è¦æ£€æŸ¥æ˜¯å¦æ˜¯dictï¼‰
                    if isinstance(output_data, dict) and output_data.get("problem_id") is not None:
                        processed_problems.add(problem_id_from_file)
                except (json.JSONDecodeError, IOError, OSError):
                    pass  # å¦‚æœæ–‡ä»¶æŸåæˆ–æ— æ³•è¯»å–ï¼Œå¿½ç•¥
    
    # è¿‡æ»¤æ‰å·²å¤„ç†çš„é—®é¢˜
    remaining_files = []
    for json_filename in filtered_files:
        problem_id_str = json_filename.split('.')[0]
        if problem_id_str not in processed_problems:
            remaining_files.append(json_filename)
    
    print(f"æ‰¾åˆ° {len(problem_files)} ä¸ªé—®é¢˜æ–‡ä»¶ï¼Œè¿‡æ»¤å {len(filtered_files)} ä¸ªé—®é¢˜åœ¨èŒƒå›´å†…ï¼Œå…¶ä¸­ {len(processed_problems)} ä¸ªå·²å¤„ç†ï¼Œå‰©ä½™ {len(remaining_files)} ä¸ªå¾…å¤„ç†ã€‚")
    
    if len(remaining_files) == 0:
        print("âœ… æ‰€æœ‰é—®é¢˜éƒ½å·²å¤„ç†å®Œæˆï¼")
        return
    
    # 2. ä¿®æ”¹ï¼šå¾ªç¯å¹¶è§£æ .json æ–‡ä»¶
    for idx, json_filename in enumerate(tqdm(remaining_files, desc="å¤„ç†è¿›åº¦"), 1):
        problem_id_str = json_filename.split('.')[0]
        json_path = os.path.join(input_dir, json_filename)
        log_entry = {"problem_id": problem_id_str}
        
        # æ˜¾ç¤ºå½“å‰å¤„ç†è¿›åº¦
        if idx % 10 == 1 or idx == len(remaining_files):
            print(f"\n[{idx}/{len(remaining_files)}] æ­£åœ¨å¤„ç†é—®é¢˜ {problem_id_str}...")

        try:
            # 3. ä»JSONä¸­è¯»å– problem_text å’Œ image_path
            with open(json_path, 'r', encoding='utf-8') as f:
                input_data = json.load(f)
            
            # è·å–é—®é¢˜æ–‡æœ¬ï¼ˆå…è®¸ä¸ºç©ºï¼Œåªè¦æœ‰å›¾ç‰‡å°±å¯ä»¥å¤„ç†ï¼‰
            problem_text = input_data.get("problem_text_en", "").strip()
            if not problem_text:
                problem_text = input_data.get("problem_text_cn", "").strip()
            if not problem_text:
                problem_text = ""  # å…è®¸ä¸ºç©ºï¼Œåªå¤„ç†å›¾ç‰‡
            
            # ä»æ–‡ä»¶åæˆ–problem_idå­—æ®µä¸­æå–é—®é¢˜ID
            problem_id = input_data.get("problem_id")
            if problem_id is None:
                # å¦‚æœJSONä¸­æ²¡æœ‰problem_idï¼Œä»æ–‡ä»¶åä¸­æå–
                try:
                    problem_id = int(problem_id_str)
                except ValueError:
                    print(f"è­¦å‘Š: æ— æ³•ä»æ–‡ä»¶å '{json_filename}' ä¸­æå–é—®é¢˜IDï¼Œå·²è·³è¿‡ã€‚")
                    log_entry.update({"status": "skipped", "reason": "Cannot extract problem_id from filename"})
                    log_data.append(log_entry)
                    continue
            else:
                problem_id = int(problem_id)
            
            # ä¼˜å…ˆä½¿ç”¨ problem_img å­—æ®µä¸­çš„è·¯å¾„
            image_path = None
            images_base_dir = "src/fgps/formalgeo7k_v2/images"
            image_extensions = ['.png', '.jpg', '.jpeg']
            
            # æ–¹æ³•1: å°è¯•ä» problem_img å­—æ®µè·å–å›¾ç‰‡è·¯å¾„
            problem_img = input_data.get("problem_img")
            if problem_img:
                if isinstance(problem_img, list) and len(problem_img) > 0:
                    img_path_str = problem_img[0]
                elif isinstance(problem_img, str):
                    img_path_str = problem_img
                else:
                    img_path_str = None
                
                if img_path_str:
                    # å¤„ç†è·¯å¾„æ ¼å¼ï¼ˆå¯èƒ½æ˜¯ Windows è·¯å¾„æ ¼å¼ images\239.jpgï¼‰
                    img_path_str = img_path_str.replace('\\', '/')
                    # æå–æ–‡ä»¶å
                    img_filename = os.path.basename(img_path_str)
                    # å°è¯•åœ¨ images ç›®å½•ä¸­æŸ¥æ‰¾
                    candidate_path = os.path.join(images_base_dir, img_filename)
                    if os.path.exists(candidate_path):
                        image_path = candidate_path
            
            # æ–¹æ³•2: å¦‚æœæ–¹æ³•1å¤±è´¥ï¼ŒæŒ‰ problem_id æŸ¥æ‰¾å›¾ç‰‡æ–‡ä»¶
            if not image_path:
                for ext in image_extensions:
                    candidate_path = os.path.join(images_base_dir, f"{problem_id}{ext}")
                    if os.path.exists(candidate_path):
                        image_path = candidate_path
                        break
            
            # å¦‚æœä»ç„¶æ‰¾ä¸åˆ°å›¾ç‰‡ï¼Œæ£€æŸ¥æ˜¯å¦è‡³å°‘æœ‰é—®é¢˜æ–‡æœ¬
            if not image_path:
                if not problem_text:
                    print(f"è­¦å‘Š: é—®é¢˜ {problem_id} æ—¢æ²¡æœ‰å›¾ç‰‡ä¹Ÿæ²¡æœ‰æ–‡æœ¬ï¼Œå·²è·³è¿‡ã€‚")
                    log_entry.update({"status": "skipped", "reason": f"No image and no text for problem_id {problem_id}"})
                    log_data.append(log_entry)
                    continue
                else:
                    # åªæœ‰æ–‡æœ¬æ²¡æœ‰å›¾ç‰‡ï¼Œä»ç„¶å¯ä»¥å¤„ç†ï¼ˆä½†ä¼šæç¤ºï¼‰
                    print(f"è­¦å‘Š: é—®é¢˜ {problem_id} æ²¡æœ‰å›¾ç‰‡æ–‡ä»¶ï¼Œå°†ä»…ä½¿ç”¨æ–‡æœ¬å¤„ç†ã€‚")
                    image_path = None  # è®¾ç½®ä¸º Noneï¼Œåç»­ä¼šå¤„ç†

        except (json.JSONDecodeError, KeyError) as e:
            print(f"è­¦å‘Š: è§£æJSONæ–‡ä»¶ '{json_filename}' æ—¶å‡ºé”™: {e}ï¼Œå·²è·³è¿‡ã€‚")
            log_entry.update({"status": "skipped", "reason": f"Error reading source JSON: {e}"})
            log_data.append(log_entry)
            continue
        
        # è°ƒç”¨APIç”Ÿæˆï¼ˆä¼ å…¥few-shotèŒƒä¾‹æ•°æ®ï¼‰
        print(f"  ğŸ“¤ è°ƒç”¨APIå¤„ç†é—®é¢˜ {problem_id_str}...")
        # å¦‚æœ image_path ä¸º Noneï¼Œä¼ é€’ None è€Œä¸æ˜¯å­—ç¬¦ä¸²
        result = generate_geometry_json(problem_text, image_path if image_path else None, golden_prompt, problem_id, few_shot_examples_data)
        
        # æ˜¾ç¤ºå¤„ç†ç»“æœ
        if result["status"] == "success":
            print(f"  âœ… é—®é¢˜ {problem_id_str} å¤„ç†æˆåŠŸ")
        else:
            print(f"  âŒ é—®é¢˜ {problem_id_str} å¤„ç†å¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')[:100]}")
        
        # ä¿å­˜å’Œæ—¥å¿—è®°å½•
        if result["status"] == "success":
            output_json_path = os.path.join(output_dir, f"{problem_id_str}.json")
            with open(output_json_path, 'w', encoding='utf-8') as f:
                json.dump(result["data"], f, indent=2, ensure_ascii=False)
            log_entry["status"] = "success"
            log_entry["output_file"] = output_json_path
            processed_problems.add(problem_id_str)  # æ ‡è®°ä¸ºå·²å¤„ç†
        else:
            log_entry["status"] = "error"
            log_entry["reason"] = result["message"]
            if "raw_output" in result:
                log_entry["raw_output"] = result["raw_output"]
        
        # æ›´æ–°æ—¥å¿—ï¼ˆæŸ¥æ‰¾æ˜¯å¦å·²æœ‰è¯¥é—®é¢˜çš„æ—¥å¿—æ¡ç›®ï¼‰
        existing_entry_index = None
        for i, entry in enumerate(log_data):
            if entry.get("problem_id") == problem_id_str:
                existing_entry_index = i
                break
        
        if existing_entry_index is not None:
            # æ›´æ–°å·²æœ‰æ¡ç›®
            log_data[existing_entry_index] = log_entry
        else:
            # æ·»åŠ æ–°æ¡ç›®
            log_data.append(log_entry)
        
        # å¢é‡ä¿å­˜æ—¥å¿—ï¼ˆæ¯å¤„ç†ä¸€ä¸ªé—®é¢˜å°±ä¿å­˜ä¸€æ¬¡ï¼Œå®ç°æ–­ç‚¹ç»­ä¼ ï¼‰
        try:
            with open(log_file_path, 'w', encoding='utf-8') as f:
                json.dump(log_data, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"âš ï¸  è­¦å‘Š: ä¿å­˜æ—¥å¿—æ–‡ä»¶å¤±è´¥: {e}")

    # æœ€ç»ˆä¿å­˜æ—¥å¿—ï¼ˆç¡®ä¿æ‰€æœ‰æ•°æ®éƒ½å·²ä¿å­˜ï¼‰
    with open(log_file_path, 'w', encoding='utf-8') as f:
        json.dump(log_data, f, indent=2, ensure_ascii=False)

    print(f"\næ‰¹é‡å¤„ç†å®Œæˆï¼ç»“æœå·²ä¿å­˜åœ¨ '{output_dir}' ç›®å½•ã€‚")
    print(f"è¯¦ç»†æ—¥å¿—è¯·è§: '{log_file_path}'")


if __name__ == '__main__':
    # --- è¯·åœ¨è¿™é‡Œé…ç½®æ‚¨çš„æ–‡ä»¶å¤¹è·¯å¾„ ---
    # å­˜æ”¾æ–°é—®é¢˜ï¼ˆ.jsonæ–‡ä»¶ï¼‰çš„æ–‡ä»¶å¤¹ - ç›´æ¥ä»åŸå§‹é—®é¢˜ç›®å½•è¯»å–
    INPUT_PROBLEM_DIR = "src/fgps/formalgeo7k_v2/problems" 
    # å­˜æ”¾è®­ç»ƒé›†ï¼ˆmanual_train_setï¼‰çš„æ–‡ä»¶å¤¹
    FEW_SHOT_EXAMPLE_DIR = "gemini/data/manual_train_set"
    # å­˜æ”¾AIç”Ÿæˆç»“æœçš„æ–‡ä»¶å¤¹
    OUTPUT_DIR = "gemini/data/generated_output"
    # è°“è¯å®šä¹‰æ–‡ä»¶
    PREDICATE_GDL_PATH = "gemini/predicate_GDL.json"
    # å¤„ç†èŒƒå›´ï¼š1-700é¢˜ç›®
    START_ID = 1
    END_ID = 700

    if not os.path.exists(INPUT_PROBLEM_DIR):
        print(f"é”™è¯¯: è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {INPUT_PROBLEM_DIR}")
        exit(1)
    if not os.path.exists(FEW_SHOT_EXAMPLE_DIR):
        print(f"è­¦å‘Š: èŒƒä¾‹ç›®å½•ä¸å­˜åœ¨: {FEW_SHOT_EXAMPLE_DIR}ï¼Œå°†ç»§ç»­ä½¿ç”¨æ— èŒƒä¾‹çš„æç¤ºè¯ã€‚")
    
    # æ˜¯å¦å¼ºåˆ¶é‡æ–°ç”Ÿæˆæ‰€æœ‰é—®é¢˜ï¼ˆå¿½ç•¥å·²å¤„ç†çš„æ ‡è®°ï¼‰
    # è®¾ç½®ä¸º True å°†é‡æ–°ç”Ÿæˆæ‰€æœ‰é—®é¢˜ï¼Œå³ä½¿ä¹‹å‰å·²ç»å¤„ç†è¿‡
    FORCE_REGENERATE = False  # è®¾ç½®ä¸º True ä»¥é‡æ–°ç”Ÿæˆæ‰€æœ‰é—®é¢˜
    
    # è¿è¡Œæ‰¹é‡å¤„ç†
    batch_process_problems(
        input_dir=INPUT_PROBLEM_DIR, 
        output_dir=OUTPUT_DIR, 
        example_dir=FEW_SHOT_EXAMPLE_DIR,
        gdl_path=PREDICATE_GDL_PATH,
        start_id=START_ID,
        end_id=END_ID,
        force_regenerate=FORCE_REGENERATE
    )
